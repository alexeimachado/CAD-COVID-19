# -*- coding: utf-8 -*-
"""YOLOv5 RSNA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XlU8Nl2WJTxvH5AMFtofv0xfvTBa2HxY

# Setup

Clone repo, install dependencies and check PyTorch and GPU.
"""

!pip install pydicom

import math
import os
import shutil
import sys

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import pydicom
import cv2
from sklearn.model_selection import train_test_split
from tqdm import tqdm

import torch
from IPython.display import Image, clear_output  # to display images

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ultralytics/yolov5  # clone repo
# %cd yolov5
# %pip install -qr requirements.txt  # install dependencies

clear_output()
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))

"""# 1. Inference

`detect.py` runs inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases).
"""

!python detect.py --weights yolov5x.pt --img 640 --conf 0.25 --source data/images/
Image(filename='runs/detect/exp/zidane.jpg', width=600)

"""Results are saved to `runs/detect`. A full list of available inference sources:
<img src="https://user-images.githubusercontent.com/26833433/98274798-2b7a7a80-1f94-11eb-91a4-70c73593e26b.jpg" width="900">

##Copiando os arquivos##
**Não funciona se tentar baixar diretamente. É preciso baixar e subir para o drive e alterar o diretório abaixo**
"""

# Download RSNA

from google.colab import drive
drive.mount('/content/drive')

# Link para o rsna
https://drive.google.com/uc?export=download&confirm=Azk1&id=1g_epyjg1UaguV8e8D9CuhDJCDfCuTv5F

# link alternativo
https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data

# link alternativo
https://www.rsna.org/education/ai-resources-and-training/ai-image-challenge/rsna-pneumonia-detection-challenge-2018


"""Não funciona se tentar baixar diretamente.
   É preciso baixar e subir para o drive e alterar o diretório abaixo.
"""

"""**Diretório a ser alterado**
**"/content/drive/MyDrive/Mestrado/Projetos/Challenge Covid-19/RSNA/rsna-pneumonia-detection-challenge.zip"**
"""

!unzip -uq "/content/drive/MyDrive/Mestrado/Projetos/Challenge Covid-19/RSNA/rsna-pneumonia-detection-challenge.zip" -d "/content/RSNA/"

"""##Convertendo os valores das labels para o formato da yolo##"""

DATA_DIR = "/content/RSNA/"

train_dcm_dir = os.path.join(DATA_DIR, "stage_2_train_images")
test_dcm_dir = os.path.join(DATA_DIR, "stage_2_test_images")

img_dir = os.path.join(os.getcwd(), "images")  # .jpg
label_dir = os.path.join(os.getcwd(), "labels")  # .txt
metadata_dir = os.path.join(os.getcwd(), "metadata") # .txt

# YOLOv3 config file directory
cfg_dir = os.path.join(os.getcwd(), "cfg")
# YOLOv3 training checkpoints will be saved here
backup_dir = os.path.join(os.getcwd(), "backup")

for directory in [img_dir, label_dir, metadata_dir, cfg_dir, backup_dir]:
    if os.path.isdir(directory):
        continue
    os.mkdir(directory)

def save_img_from_dcm(dcm_dir, img_dir, patient_id):
    img_fp = os.path.join(img_dir, "{}.png".format(patient_id))
    if os.path.exists(img_fp):
        return
    dcm_fp = os.path.join(dcm_dir, "{}.dcm".format(patient_id))
    img_1ch = pydicom.read_file(dcm_fp).pixel_array
    img_3ch = np.stack([img_1ch]*3, -1)

    img_fp = os.path.join(img_dir, "{}.png".format(patient_id))
    cv2.imwrite(img_fp, img_3ch)
    
def save_label_from_dcm(label_dir, patient_id, row=None):
    # rsna defualt image size
    img_size = 1024
    label_fp = os.path.join(label_dir, "{}.txt".format(patient_id))
    
    f = open(label_fp, "a")
    if row is None:
        f.close()
        return

    top_left_x = row[1]
    top_left_y = row[2]
    w = row[3]
    h = row[4]
    
    # 'r' means relative. 'c' means center.
    rx = top_left_x/img_size
    ry = top_left_y/img_size
    rw = w/img_size
    rh = h/img_size
    rcx = rx+rw/2
    rcy = ry+rh/2
    
    line = "{} {} {} {} {}\n".format(0, rcx, rcy, rw, rh)
    
    f.write(line)
    f.close()
        
def save_yolov3_data_from_rsna(dcm_dir, img_dir, label_dir, annots):
    for row in tqdm(annots.values):
        patient_id = row[0]

        img_fp = os.path.join(img_dir, "{}.png".format(patient_id))
        if os.path.exists(img_fp):
            save_label_from_dcm(label_dir, patient_id, row)
            continue

        target = row[5]
        # Since kaggle kernel have samll volume (5GB ?), I didn't contain files with no bbox here.
        if target == 0:
            continue
        save_label_from_dcm(label_dir, patient_id, row)
        save_img_from_dcm(dcm_dir, img_dir, patient_id)

annots = pd.read_csv(os.path.join(DATA_DIR, "stage_2_train_labels.csv"))
annots.head()

save_yolov3_data_from_rsna(train_dcm_dir, img_dir, label_dir, annots)

!du -sh images labels

"""**Plotando uma sample**"""

ex_patient_id = annots[annots.Target == 1].patientId.values[0]
ex_img_path = os.path.join(img_dir, "{}.png".format(ex_patient_id))
ex_label_path = os.path.join(label_dir, "{}.txt".format(ex_patient_id))

plt.imshow(cv2.imread(ex_img_path))

img_size = 1014
with open(ex_label_path, "r") as f:
    for line in f:
        print(line)
        class_id, rcx, rcy, rw, rh = list(map(float, line.strip().split()))
        x = (rcx-rw/2)*img_size
        y = (rcy-rh/2)*img_size
        w = rw*img_size
        h = rh*img_size
        plt.plot([x, x, x+w, x+w, x], [y, y+h, y+h, y, y])

"""**Gerando um arquivo contendo os arquivos de treino e validação**"""

random_stat = 123
np.random.seed(random_stat)

def write_train_list(metadata_dir, img_dir, name, series):
    list_fp = os.path.join(metadata_dir, name)
    with open(list_fp, "w") as f:
        for patient_id in series:
            line = "{}\n".format(os.path.join(img_dir, "{}.png".format(patient_id)))
            f.write(line)

# Following lines do not contain data with no bbox
patient_id_series = annots[annots.Target == 1].patientId.drop_duplicates()

tr_series, val_series = train_test_split(patient_id_series, test_size=0.1, random_state=random_stat)
print("The # of train set: {}, The # of validation set: {}".format(tr_series.shape[0], val_series.shape[0]))

# train image path list
write_train_list(metadata_dir, img_dir, "tr_list.txt", tr_series)
# validation image path list
write_train_list(metadata_dir, img_dir, "val_list.txt", val_series)

"""**Criando o conjunto de teste**"""

def save_yolov3_test_data(test_dcm_dir, img_dir, metadata_dir, name, series):
    list_fp = os.path.join(metadata_dir, name)
    with open(list_fp, "w") as f:
        for patient_id in series:
            save_img_from_dcm(test_dcm_dir, img_dir, patient_id)
            line = "{}\n".format(os.path.join(img_dir, "{}.png".format(patient_id)))
            f.write(line)

test_dcm_fps = list(set(glob.glob(os.path.join(test_dcm_dir, '*.dcm'))))
test_dcm_fps = pd.Series(test_dcm_fps).apply(lambda dcm_fp: dcm_fp.strip().split("/")[-1].replace(".dcm",""))

save_yolov3_test_data(test_dcm_dir, img_dir, metadata_dir, "te_list.txt", test_dcm_fps)

"""**Plotando uma sample de teste**"""

ex_patient_id = test_dcm_fps[0]
ex_img_path = os.path.join(img_dir, "{}.png".format(ex_patient_id))

plt.imshow(cv2.imread(ex_img_path))

!zip -r /content/yolov5/images.zip /content/yolov5/images/

!zip -r /content/yolov5/labels.zip /content/yolov5/labels

!zip -r /content/yolov5/metadados.zip /content/yolov5/metadata/

from google.colab import files
files.download("/content/yolov5/images.zip")

files.download("/content/yolov5/labels.zip")

files.download("/content/yolov5/metadados.zip")

!rm -r "/content/RSNA"

"""##Alterando o arquivo de configurações para o número de classes corretas##"""

contents = '''

# COCO 2017 dataset http://cocodataset.org
# Train command: python train.py --data coco.yaml
# Default dataset location is next to /yolov5:
#   /parent_folder
#     /coco
#     /yolov5


# download command/URL (optional)
#download: bash data/scripts/get_coco.sh

# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
train: /content/yolov5/metadata/tr_list.txt  # 118287 images
val: /content/yolov5/metadata/val_list.txt  # 5000 images
test: /content/yolov5/metadata/te_list.txt  # 20288 of 40670 images

# number of classes
nc: 1

# class names
names: [ 'pneumonia' ]

# Print classes
# with open('data/coco.yaml') as f:
#   d = yaml.load(f, Loader=yaml.FullLoader)  # dict
#   for i, x in enumerate(d['names']):
#     print(i, x)
'''

f = open('/content/yolov5/cfg/rsna.yaml','w')
f.write(contents)
f.close()

"""##Alterando o arquivo de treino##"""

content  = '''
# parameters
nc: 1  # number of classes
depth_multiple: 1.33  # model depth multiple
width_multiple: 1.25  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, C3, [1024, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
'''
f = open('/content/yolov5/cfg/rsna_cfg.yaml','w')
f.write(content)
f.close()

"""##Treinando##"""

!python train.py --img 320 --batch 48 --epochs 100 --data /content/yolov5/cfg/rsna.yaml --weights '' --cfg /content/yolov5/cfg/rsna_cfg.yaml --cache --adam --linear-lr

!cp -r "/content/yolov5/runs/train/exp" "/content/drive/MyDrive/Mestrado/Projetos/Challenge Covid-19/RSNA/Teste_10-03_Scratch"

"""# 3. Visualize

## Local Logging

All results are logged by default to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc. View train and test jpgs to see mosaics, labels, predictions and augmentation effects. Note a **Mosaic Dataloader** is used for training (shown below), a new concept developed by Ultralytics and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934).
"""

#Image(filename='runs/train/exp3/train_batch0.jpg', width=800)  # train batch 0 mosaics and labels
#Image(filename='runs/train/exp3/test_batch0_labels.jpg', width=800)  # test batch 0 labels
Image(filename='runs/train/exp3/test_batch0_pred.jpg', width=800)  # test batch 0 predictions

"""Training losses and performance metrics are also logged to [Tensorboard](https://www.tensorflow.org/tensorboard) and a custom `results.txt` logfile which is plotted as `results.png` (below) after training completes. Here we show YOLOv5s trained on COCO128 to 300 epochs, starting from scratch (blue), and from pretrained `--weights yolov5s.pt` (orange)."""

from utils.plots import plot_results 
plot_results(save_dir='runs/train/exp3')  # plot all results*.txt as results.png
Image(filename='runs/train/exp3/results.png', width=800)